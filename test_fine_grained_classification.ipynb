{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0171cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from os.path import join, exists\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81016dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from test_zero_shot_classification import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e92fdd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please specify the root directory to benchmark datasets \n",
    "ROOT_DATA_DIR = '/PATH/TO/THE/ROOT/DIRECTORY/OF/BENCHMARK/DATASETS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b870081c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(20, 20))\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "be6df78d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 78.17it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 640/640 [00:04<00:00, 148.89it/s]\n"
     ]
    }
   ],
   "source": [
    "k = 'roof_shape' # fine-grained task name. One of ['roof_shape', 'smoothness', 'surface']\n",
    "assert k in ['roof_shape', 'smoothness', 'surface']\n",
    "\n",
    "label_col = 'label_v1' # 'label_v1' or 'label_v2'\n",
    "assert label_col in ['label_v1', 'label_v2']\n",
    "\n",
    "model = 'ViT-L-14'\n",
    "pretrained = 'THE/PATH/TO/MODEL/CHECKPOINT' # replace this with the path to a model checkpoint (.pt file)\n",
    "\n",
    "if label_col == 'label_v1':\n",
    "    classnames = join(ROOT_DATA_DIR, k, 'classnames_v1.txt')\n",
    "else:\n",
    "    classnames = join(ROOT_DATA_DIR, k, 'classnames_v2.txt')\n",
    "test_data = join(ROOT_DATA_DIR, k, 'img_txt_pairs_test.csv')\n",
    "\n",
    "arg_list = [\n",
    "    '--root-data-dir=' + ROOT_DATA_DIR,\n",
    "    '--classification-mode=multiclass',\n",
    "    '--csv-separator=,', \n",
    "    '--csv-img-key', 'filepath', \n",
    "    '--csv-class-key', label_col, \n",
    "    '--batch-size=128', \n",
    "    '--workers=8', \n",
    "    '--model=' +  model, \n",
    "    '--pretrained=' + pretrained, \n",
    "    '--test-data=' + test_data, \n",
    "    '--classnames=' + classnames,\n",
    "    '--test-data-name=' + k,\n",
    "    '--debugging',\n",
    "]\n",
    "\n",
    "if model == 'ViT-L-14':\n",
    "    arg_list.append('--force-quick-gelu') # This is because the ViT-L-14 model is initialized with the OpenAI model\n",
    "\n",
    "results = test(arg_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1632b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6227272727272727, 1.0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top-1 and top-5 accuracies\n",
    "results[k + '-top1'], results[k + '-top5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8724bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot confusion matrix\n",
    "label_list = []\n",
    "with open(classnames, 'r') as f:\n",
    "    for line in f:\n",
    "        label_list.append(line.strip())\n",
    "\n",
    "plot_confusion_matrix(results[k.replace(':', '_') + '-labels'], \n",
    "                      results[k.replace(':', '_') + '-predictions'], \n",
    "                      classes=np.array(label_list), normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7dd932f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_latest_p37)",
   "language": "python",
   "name": "conda_pytorch_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
